{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement 1"
      ],
      "metadata": {
        "id": "Fx2EST722qe1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple RNN Model"
      ],
      "metadata": {
        "id": "rAi1cN54GQhQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "k_Ack-Kcan6w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LQfdv2GEewZF"
      },
      "outputs": [],
      "source": [
        "#data\n",
        "data = pd.read_csv('/content/name_gender.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "zVeQ7w2IfE0B",
        "outputId": "73b174b6-0f24-4937-973e-733571f267a0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        name gender  probability\n",
              "0      Aaban      M          1.0\n",
              "1      Aabha      F          1.0\n",
              "2      Aabid      M          1.0\n",
              "3  Aabriella      F          1.0\n",
              "4       Aada      F          1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1dcc870e-774f-4fc5-bdff-feb0361d8433\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>gender</th>\n",
              "      <th>probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Aaban</td>\n",
              "      <td>M</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Aabha</td>\n",
              "      <td>F</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Aabid</td>\n",
              "      <td>M</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aabriella</td>\n",
              "      <td>F</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Aada</td>\n",
              "      <td>F</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1dcc870e-774f-4fc5-bdff-feb0361d8433')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1dcc870e-774f-4fc5-bdff-feb0361d8433 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1dcc870e-774f-4fc5-bdff-feb0361d8433');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eqCpKum2fOL8"
      },
      "outputs": [],
      "source": [
        "#remove non-ASCII characters\n",
        "data['name'] = data['name'].apply(lambda x: ''.join([i for i in x if i in string.ascii_letters]))\n",
        "\n",
        "#convert each name into a sequence of one-hot encoded characters\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(data['name'])\n",
        "\n",
        "max_len = max([len(i) for i in data['name']])\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(data['name'])\n",
        "X = pad_sequences(X, maxlen=max_len, padding='post')\n",
        "\n",
        "#create one-hot encoded representation\n",
        "X_one_hot= np.array([np.eye(vocab_size+1)[i] for i in X])\n",
        "\n",
        "#convert the labels to binary values\n",
        "y = pd.get_dummies(data['gender'])['F']\n",
        "y = np.array(y)\n",
        "\n",
        "#split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rsjl_WLcmzoQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#split the data into 80% train and 20% test\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "#define the subset sizes\n",
        "subset_sizes = [0.25, 0.5, 0.75, 1.0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Wr4OCgh_kUn9"
      },
      "outputs": [],
      "source": [
        "#build the model with Simple RNN layer\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size+1, output_dim=32, input_length=max_len))\n",
        "model.add(SimpleRNN(32))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "#compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7y5BiL7rGwR",
        "outputId": "4e22f959-714e-467e-9356-2ee39a39b7ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset size:' 0.25%, 'Simple RNN Test accuracy:' 0.845\n",
            "Subset size:' 0.5%, 'Simple RNN Test accuracy:' 0.848\n",
            "Subset size:' 0.75%, 'Simple RNN Test accuracy:' 0.861\n",
            "Subset size:' 1.0%, 'Simple RNN Test accuracy:' 0.857\n"
          ]
        }
      ],
      "source": [
        "#loop over the subset sizes\n",
        "for subset_size in subset_sizes:\n",
        "    #calculate the number of samples for the subset\n",
        "    num_samples = int(subset_size * len(train_data))\n",
        "\n",
        "    #randomly select the subset\n",
        "    subset_indices = np.random.choice(len(train_data), size=num_samples, replace=False)\n",
        "    subset_data = train_data[subset_indices]\n",
        "    subset_labels = train_labels[subset_indices]\n",
        "\n",
        "    #build the model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=vocab_size+1, output_dim=32, input_length=max_len))\n",
        "    model.add(SimpleRNN(32))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    #compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    #train a model on the subset\n",
        "    model.fit(subset_data, subset_labels, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "    #evaluate the model on the test data\n",
        "    loss, accuracy = model.evaluate(test_data, test_labels, verbose=0)\n",
        "\n",
        "    #print the results\n",
        "    print(f\"Subset size:' {subset_size}%, 'Simple RNN Test accuracy:' {accuracy:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJvUULhKtVbk"
      },
      "source": [
        "#### LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dKA7H_mwtFIP"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding\n",
        "\n",
        "#define the LSTM model\n",
        "def build_lstm_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size+1, output_dim=32, input_length=max_len),\n",
        "        LSTM(64, dropout=0.2, recurrent_dropout=0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YaVKFRI2tkEI",
        "outputId": "956c19af-87b4-4a8f-9117-81b29a093654"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset size: 0.25%, LSTM Test accuracy: 0.839\n",
            "Subset size: 0.5%, LSTM Test accuracy: 0.851\n",
            "Subset size: 0.75%, LSTM Test accuracy: 0.864\n",
            "Subset size: 1.0%, LSTM Test accuracy: 0.874\n"
          ]
        }
      ],
      "source": [
        "#loop over the subset sizes\n",
        "for subset_size in subset_sizes:\n",
        "    #calculate the number of samples for the subset\n",
        "    num_samples = int(subset_size * len(train_data))\n",
        "\n",
        "    #randomly select the subset\n",
        "    subset_indices = np.random.choice(len(train_data), size=num_samples, replace=False)\n",
        "    subset_data = train_data[subset_indices]\n",
        "    subset_labels = train_labels[subset_indices]\n",
        "\n",
        "    #train the LSTM model on the full dataset\n",
        "    lstm_model = build_lstm_model()\n",
        "    lstm_model.fit(subset_data, subset_labels, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "\n",
        "    #evaluate the model on the test data\n",
        "    loss, accuracy = lstm_model.evaluate(test_data, test_labels, verbose=0)\n",
        "\n",
        "    #print the results\n",
        "    print(f\"Subset size: {subset_size}%, LSTM Test accuracy: {accuracy:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU Model"
      ],
      "metadata": {
        "id": "-yf0X2Xv2msK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout, Embedding\n",
        "\n",
        "#define the GRU model\n",
        "def build_gru_model():\n",
        "    model = Sequential([\n",
        "        Embedding(vocab_size+1, output_dim=32 , input_length=max_len),\n",
        "        GRU(64, dropout=0.2, recurrent_dropout=0.2),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "x3O8J1GfseyH"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loop over the subset sizes\n",
        "for subset_size in subset_sizes:\n",
        "    #calculate the number of samples for the subset\n",
        "    num_samples = int(subset_size * len(train_data))\n",
        "\n",
        "    #randomly select the subset\n",
        "    subset_indices = np.random.choice(len(train_data), size=num_samples, replace=False)\n",
        "    subset_data = train_data[subset_indices]\n",
        "    subset_labels = train_labels[subset_indices]\n",
        "\n",
        "    #train the GRU model on the full dataset\n",
        "    gru_model = build_gru_model()\n",
        "    gru_model.fit(subset_data, subset_labels, epochs=10, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "    #evaluate the GRU model on the test data\n",
        "    loss, accuracy = gru_model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "    #print the results\n",
        "    print(f\"Subset size: {subset_size}%, GRU Test accuracy: {accuracy:0.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhVddE7YusOj",
        "outputId": "c2f426c6-454e-419a-98db-ea88d899ada2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset size: 0.25%, GRU Test accuracy: 0.839\n",
            "Subset size: 0.5%, GRU Test accuracy: 0.851\n",
            "Subset size: 0.75%, GRU Test accuracy: 0.862\n",
            "Subset size: 1.0%, GRU Test accuracy: 0.873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Statement 2"
      ],
      "metadata": {
        "id": "Z4LXfOT222eo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import string\n",
        "from string import digits\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, SimpleRNN, Embedding\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers import Dense, Activation\n",
        "from keras.optimizers import RMSprop"
      ],
      "metadata": {
        "id": "4poP8hqzKlzd"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data\n",
        "names=pd.read_csv('/content/name_gender.csv')"
      ],
      "metadata": {
        "id": "CEEy6dIvK_n7"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "male_names = names.loc[names['gender'] == 'M', 'name']\n",
        "female_names = names.loc[names['gender'] == 'F', 'name']"
      ],
      "metadata": {
        "id": "BXxHslqoLDSV"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "male_names = male_names.apply(lambda x: x.lower())\n",
        "female_names = female_names.apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "zND4rcMfLGNn"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "male_names=pd.DataFrame({'name':male_names.unique()})\n",
        "female_names=pd.DataFrame({'name':female_names.unique()})"
      ],
      "metadata": {
        "id": "mpH7Ee2NLf9X"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For Male Names"
      ],
      "metadata": {
        "id": "US3ruVf-L-zN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(male_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BqIuT6wcQHb8",
        "outputId": "0bced22c-cc79-4902-cef0-701934cb9be5"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to delay target by one timestamp\n",
        "male_names['name']=male_names.name.apply(lambda x:'\\t'+x)"
      ],
      "metadata": {
        "id": "PjY-DCVLLlmI"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to indicate end of the word\n",
        "male_names['target']=male_names.name.apply(lambda x:x[1:len(x)]+'\\n')"
      ],
      "metadata": {
        "id": "tKqgxZ_rNL3R"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a list\n",
        "lenght_list_male=[]\n",
        "for l in male_names.name:\n",
        "    lenght_list_male.append(len(l))\n",
        "max_len = np.max(lenght_list_male)\n",
        "\n",
        "#the vocab dict\n",
        "all_chars_male=set()\n",
        "for name in male_names.name:\n",
        "    for c in name:\n",
        "        if c not in all_chars_male:\n",
        "            all_chars_male.add(c)\n",
        "all_chars_male.add('\\n')\n",
        "\n",
        "char_to_ix = { ch:i for i,ch in enumerate(sorted(all_chars_male)) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(sorted(all_chars_male)) }"
      ],
      "metadata": {
        "id": "m_uVxWX9NP1j"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = np.zeros((len(male_names.name), max_len, 28),dtype='float32')\n",
        "output_data = np.zeros((len(male_names.name), max_len, 28),dtype='float32')\n",
        "\n",
        "#generate input and output data\n",
        "for i, x in enumerate(male_names.name):\n",
        "    for t, ch in enumerate(x):\n",
        "        input_data[i, t, char_to_ix[ch]] = 1\n",
        "for i, x in enumerate(male_names.target):\n",
        "    for t, ch in enumerate(x):\n",
        "        output_data[i,t, char_to_ix[ch]] = 1"
      ],
      "metadata": {
        "id": "pCj5OlQmNyDB"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model for generating new names\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(max_len, len(all_chars_male)), return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(all_chars_male))))\n",
        "model.add(TimeDistributed(Activation('softmax')))\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoNz2fJpN79L",
        "outputId": "e36cc247-c61e-463b-f70c-fd75d2c20ba4"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "model.fit(input_data, output_data, batch_size=32,epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBUkUYsYOSdn",
        "outputId": "45d49d0d-07b2-4262-a681-6c7f300516a6"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1086/1086 [==============================] - 15s 12ms/step - loss: 1.0274\n",
            "Epoch 2/50\n",
            "1086/1086 [==============================] - 15s 14ms/step - loss: 0.9639\n",
            "Epoch 3/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9457\n",
            "Epoch 4/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9362\n",
            "Epoch 5/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9299\n",
            "Epoch 6/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9248\n",
            "Epoch 7/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9214\n",
            "Epoch 8/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9185\n",
            "Epoch 9/50\n",
            "1086/1086 [==============================] - 14s 13ms/step - loss: 0.9160\n",
            "Epoch 10/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9140\n",
            "Epoch 11/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9124\n",
            "Epoch 12/50\n",
            "1086/1086 [==============================] - 15s 14ms/step - loss: 0.9112\n",
            "Epoch 13/50\n",
            "1086/1086 [==============================] - 19s 18ms/step - loss: 0.9097\n",
            "Epoch 14/50\n",
            "1086/1086 [==============================] - 19s 17ms/step - loss: 0.9087\n",
            "Epoch 15/50\n",
            "1086/1086 [==============================] - 20s 18ms/step - loss: 0.9078\n",
            "Epoch 16/50\n",
            "1086/1086 [==============================] - 15s 13ms/step - loss: 0.9072\n",
            "Epoch 17/50\n",
            "1086/1086 [==============================] - 14s 12ms/step - loss: 0.9062\n",
            "Epoch 18/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9054\n",
            "Epoch 19/50\n",
            "1086/1086 [==============================] - 16s 15ms/step - loss: 0.9050\n",
            "Epoch 20/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9042\n",
            "Epoch 21/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9039\n",
            "Epoch 22/50\n",
            "1086/1086 [==============================] - 14s 13ms/step - loss: 0.9032\n",
            "Epoch 23/50\n",
            "1086/1086 [==============================] - 18s 16ms/step - loss: 0.9028\n",
            "Epoch 24/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9024\n",
            "Epoch 25/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9022\n",
            "Epoch 26/50\n",
            "1086/1086 [==============================] - 14s 13ms/step - loss: 0.9017\n",
            "Epoch 27/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9011\n",
            "Epoch 28/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9009\n",
            "Epoch 29/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9004\n",
            "Epoch 30/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.9003\n",
            "Epoch 31/50\n",
            "1086/1086 [==============================] - 15s 14ms/step - loss: 0.9000\n",
            "Epoch 32/50\n",
            "1086/1086 [==============================] - 15s 14ms/step - loss: 0.8998\n",
            "Epoch 33/50\n",
            "1086/1086 [==============================] - 15s 14ms/step - loss: 0.8993\n",
            "Epoch 34/50\n",
            "1086/1086 [==============================] - 15s 14ms/step - loss: 0.8991\n",
            "Epoch 35/50\n",
            "1086/1086 [==============================] - 14s 13ms/step - loss: 0.8992\n",
            "Epoch 36/50\n",
            "1086/1086 [==============================] - 14s 13ms/step - loss: 0.8988\n",
            "Epoch 37/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.8988\n",
            "Epoch 38/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.8983\n",
            "Epoch 39/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.8982\n",
            "Epoch 40/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.8977\n",
            "Epoch 41/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.8979\n",
            "Epoch 42/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.8979\n",
            "Epoch 43/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.8975\n",
            "Epoch 44/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.8974\n",
            "Epoch 45/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.8970\n",
            "Epoch 46/50\n",
            "1086/1086 [==============================] - 13s 12ms/step - loss: 0.8968\n",
            "Epoch 47/50\n",
            "1086/1086 [==============================] - 14s 12ms/step - loss: 0.8969\n",
            "Epoch 48/50\n",
            "1086/1086 [==============================] - 14s 13ms/step - loss: 0.8968\n",
            "Epoch 49/50\n",
            "1086/1086 [==============================] - 14s 13ms/step - loss: 0.8966\n",
            "Epoch 50/50\n",
            "1086/1086 [==============================] - 15s 14ms/step - loss: 0.8966\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb83c13d00>"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating"
      ],
      "metadata": {
        "id": "83hiwB1lQjju"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize an empty list to store generated male names\n",
        "male_names = []\n",
        "\n",
        "#generate 100 male names\n",
        "for i in range(100):\n",
        "    stop=False\n",
        "    ch='\\t'\n",
        "    counter=1\n",
        "    \n",
        "    #initialize the target sequence with a tab character\n",
        "    target_seq = np.zeros((1, max_len, 28))\n",
        "    target_seq[0, 0, char_to_ix[ch]] = 1.\n",
        "    \n",
        "    #generate the name one character at a time until a newline character is encountered or the name exceeds 10 characters\n",
        "    while stop == False and counter < 10:\n",
        "        \n",
        "        #use the model to predict the probabilities of the next character\n",
        "        probs = model.predict(target_seq, verbose=0)[:,counter-1,:]\n",
        "        \n",
        "        #sample the next character based on the predicted probabilities\n",
        "        c= np.random.choice(sorted(list(all_chars_male)), replace =False,p=probs.reshape(28))\n",
        "        \n",
        "        #newline character is generated, stop generating the name\n",
        "        if c =='\\n':\n",
        "            stop=True\n",
        "        else:\n",
        "            #append the generated character to the name\n",
        "            ch=ch+c\n",
        "            \n",
        "            #update the target sequence with the generated character\n",
        "            target_seq[0,counter , char_to_ix[c]] = 1.\n",
        "            \n",
        "            #increment the counter to move to the next character\n",
        "            counter=counter+1\n",
        "    \n",
        "    #append the generated name to the list of male names\n",
        "    male_names.append(ch)\n"
      ],
      "metadata": {
        "id": "NWtokamERv_p"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_male_names = []\n",
        "for i in male_names:\n",
        "  k = i.replace('\\t','')\n",
        "  new_male_names.append(k)"
      ],
      "metadata": {
        "id": "zJySTJAGPs39"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_male_names = [name.capitalize() for name in new_male_names]\n",
        "print(len(generated_male_names))\n",
        "print(generated_male_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "73luO5lDPzzh",
        "outputId": "e639458b-a351-4b43-ee4f-9967a0d1a37f"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "['Jayton', 'Ladarrius', 'Luispatro', 'Moeeur', 'Hiji', 'Bighdon', 'Zahiar', 'Wathael', 'Carno', 'Dryone', 'Anderson', 'Juzaiah', 'Singile', 'Sumaurica', 'Maxamimin', 'Ashad', 'Jourdan', 'Crisa', 'Indabi', 'Shalan', 'Taqoard', 'Reymando', 'Alfier', 'Sadmon', 'Eliamalea', 'Wiianlaan', 'Tarion', 'Isaahirie', 'Nicoro', 'Garerios', 'Jaquens', 'Antonioh', 'Sajuan', 'Hoksen', 'Malhian', 'Rippen', 'Artayiq', 'Edley', 'Velddrick', 'Muller', 'Gerron', 'Kristhiha', 'Colley', 'Jatavion', 'Nicolos', 'Tyhir', 'Keimari', 'Jaysen', 'Osben', 'Dieonelo', 'Irick', 'Broynar', 'Marvion', 'Shiger', 'Macaley', 'Crosken', 'Tibo', 'Quintta', 'Jeonte', 'Laymander', 'Aironfoin', 'Ruyina', 'Quamasle', 'Dawarde', 'Michuaz', 'Robig', 'Burvee', 'Babtham', 'Safr', 'Fardyn', 'Gilan', 'Kamoud', 'Delnas', 'Berthimy', 'Jacarion', 'Ahmaa', 'Demondr', 'Lakardo', 'Alosy', 'Tymon', 'Riz', 'Hamet', 'Gandarius', 'Abdihanis', 'Jakiyon', 'Muntio', 'Yuner', 'Khadeal', 'Rudaun', 'Zayden', 'Carstin', 'Habdeefor', 'Herucz', 'Ferrick', 'Lavuon', 'Lawordy', 'Lafred', 'Davis', 'Jeff', 'Sherul']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "DA1RjpEUQnaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting into dataframe\n",
        "df_male = pd.DataFrame(generated_male_names, columns = ['name'])"
      ],
      "metadata": {
        "id": "wctMEVM3QW6e"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_male['gender'] = np.repeat('M', 100)"
      ],
      "metadata": {
        "id": "bOFnp2giSNv4"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_male.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Mu5Q3esmSYj7",
        "outputId": "a5e35eda-25c7-4ab2-d9cd-0b7af050af99"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        name gender\n",
              "0     Jayton      M\n",
              "1  Ladarrius      M\n",
              "2  Luispatro      M\n",
              "3     Moeeur      M\n",
              "4       Hiji      M"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57755425-8530-4647-9e9d-bc3fcb8b02bc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Jayton</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ladarrius</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Luispatro</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Moeeur</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hiji</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57755425-8530-4647-9e9d-bc3fcb8b02bc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57755425-8530-4647-9e9d-bc3fcb8b02bc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57755425-8530-4647-9e9d-bc3fcb8b02bc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove non-ASCII characters\n",
        "df_male['name'] = df_male['name'].apply(lambda x: ''.join([i for i in x if i in string.ascii_letters]))\n",
        "\n",
        "#convert each name into a sequence of one-hot encoded characters\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(df_male['name'])\n",
        "\n",
        "max_len = max([len(i) for i in df_male['name']])\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df_male['name'])\n",
        "X = pad_sequences(X, maxlen=max_len, padding='post')\n",
        "\n",
        "#create one-hot encoded representation\n",
        "X_one_hot= np.array([np.eye(vocab_size+1)[i] for i in X])\n",
        "\n",
        "#convert the labels to binary values\n",
        "y = pd.get_dummies(df_male['gender'])['M']\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "yaUkurV564Xx"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best performing model among Simple RNN, LSTM and GRU is LSTM."
      ],
      "metadata": {
        "id": "Y_Xa_sODX49S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model on the test data\n",
        "loss, accuracy = lstm_model.evaluate(X, y, verbose=0)\n",
        "\n",
        "#print the results\n",
        "print(f\"Male Accuracy using LSTM: {accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZiTI3WvXz1o",
        "outputId": "9a0079a1-e3cc-4d65-9a35-13ce59f759c9"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Male Accuracy using LSTM: 0.320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For Females Names"
      ],
      "metadata": {
        "id": "Y-mXalFrUvYe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(female_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LX0JrBnXU9Vq",
        "outputId": "27e92c3d-6f4d-45da-a7ae-587d9696a5ee"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to delay target by one timestamp\n",
        "female_names['name']=female_names.name.apply(lambda x:'\\t'+x)"
      ],
      "metadata": {
        "id": "LS8DWNdbVEyG"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to indicate end of the word\n",
        "female_names['target']=female_names.name.apply(lambda x:x[1:len(x)]+'\\n')"
      ],
      "metadata": {
        "id": "Cu-HZpT6VFVG"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a list\n",
        "lenght_list_female=[]\n",
        "for l in female_names.name:\n",
        "    lenght_list_female.append(len(l))\n",
        "max_len = np.max(lenght_list_female)\n",
        "\n",
        "#the vocab dict\n",
        "all_chars_female=set()\n",
        "for name in female_names.name:\n",
        "    for c in name:\n",
        "        if c not in all_chars_female:\n",
        "            all_chars_female.add(c)\n",
        "all_chars_female.add('\\n')\n",
        "\n",
        "char_to_ix = { ch:i for i,ch in enumerate(sorted(all_chars_female)) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(sorted(all_chars_female)) }"
      ],
      "metadata": {
        "id": "K1Cqw5T7VI1e"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = np.zeros((len(female_names.name), max_len, 28),dtype='float32')\n",
        "output_data = np.zeros((len(female_names.name), max_len, 28),dtype='float32')\n",
        "\n",
        "#generate input and output data\n",
        "for i, x in enumerate(female_names.name):\n",
        "    for t, ch in enumerate(x):\n",
        "        input_data[i, t, char_to_ix[ch]] = 1\n",
        "for i, x in enumerate(female_names.target):\n",
        "    for t, ch in enumerate(x):\n",
        "        output_data[i,t, char_to_ix[ch]] = 1"
      ],
      "metadata": {
        "id": "-C5Xg7u3VNsd"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model for generating new names\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, input_shape=(max_len, len(all_chars_male)), return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(len(all_chars_male))))\n",
        "model.add(TimeDistributed(Activation('softmax')))\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DZswRXuVcS7",
        "outputId": "5e87821d-e155-46c2-c7ee-fa750460ee28"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "model.fit(input_data, output_data, batch_size=32,epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLko-OVWViVI",
        "outputId": "e38badf3-f2cf-4d7e-d5f4-4d0139abc4e8"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1885/1885 [==============================] - 26s 13ms/step - loss: 0.9271\n",
            "Epoch 2/50\n",
            "1885/1885 [==============================] - 29s 15ms/step - loss: 0.8756\n",
            "Epoch 3/50\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8640\n",
            "Epoch 4/50\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8579\n",
            "Epoch 5/50\n",
            "1885/1885 [==============================] - 22s 12ms/step - loss: 0.8540\n",
            "Epoch 6/50\n",
            "1885/1885 [==============================] - 27s 14ms/step - loss: 0.8511\n",
            "Epoch 7/50\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8489\n",
            "Epoch 8/50\n",
            "1885/1885 [==============================] - 27s 14ms/step - loss: 0.8473\n",
            "Epoch 9/50\n",
            "1885/1885 [==============================] - 28s 15ms/step - loss: 0.8461\n",
            "Epoch 10/50\n",
            "1885/1885 [==============================] - 29s 15ms/step - loss: 0.8448\n",
            "Epoch 11/50\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8439\n",
            "Epoch 12/50\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8430\n",
            "Epoch 13/50\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8424\n",
            "Epoch 14/50\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8418\n",
            "Epoch 15/50\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8412\n",
            "Epoch 16/50\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8407\n",
            "Epoch 17/50\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8405\n",
            "Epoch 18/50\n",
            "1885/1885 [==============================] - 27s 14ms/step - loss: 0.8399\n",
            "Epoch 19/50\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8396\n",
            "Epoch 20/50\n",
            "1885/1885 [==============================] - 27s 14ms/step - loss: 0.8392\n",
            "Epoch 21/50\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8388\n",
            "Epoch 22/50\n",
            "1885/1885 [==============================] - 27s 14ms/step - loss: 0.8386\n",
            "Epoch 23/50\n",
            "1885/1885 [==============================] - 26s 14ms/step - loss: 0.8384\n",
            "Epoch 24/50\n",
            "1885/1885 [==============================] - 25s 13ms/step - loss: 0.8380\n",
            "Epoch 25/50\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8379\n",
            "Epoch 26/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8377\n",
            "Epoch 27/50\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8373\n",
            "Epoch 28/50\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8371\n",
            "Epoch 29/50\n",
            "1885/1885 [==============================] - 24s 12ms/step - loss: 0.8371\n",
            "Epoch 30/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8369\n",
            "Epoch 31/50\n",
            "1885/1885 [==============================] - 22s 12ms/step - loss: 0.8367\n",
            "Epoch 32/50\n",
            "1885/1885 [==============================] - 27s 14ms/step - loss: 0.8365\n",
            "Epoch 33/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8362\n",
            "Epoch 34/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8361\n",
            "Epoch 35/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8362\n",
            "Epoch 36/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8357\n",
            "Epoch 37/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8356\n",
            "Epoch 38/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8356\n",
            "Epoch 39/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8354\n",
            "Epoch 40/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8353\n",
            "Epoch 41/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8352\n",
            "Epoch 42/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8349\n",
            "Epoch 43/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8349\n",
            "Epoch 44/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8346\n",
            "Epoch 45/50\n",
            "1885/1885 [==============================] - 24s 12ms/step - loss: 0.8346\n",
            "Epoch 46/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8344\n",
            "Epoch 47/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8344\n",
            "Epoch 48/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8344\n",
            "Epoch 49/50\n",
            "1885/1885 [==============================] - 24s 13ms/step - loss: 0.8343\n",
            "Epoch 50/50\n",
            "1885/1885 [==============================] - 23s 12ms/step - loss: 0.8339\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb81b31400>"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating"
      ],
      "metadata": {
        "id": "AsfYRw5_VslO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize an empty list to store generated male names\n",
        "female_names = []\n",
        "\n",
        "#generate 100 male names\n",
        "for i in range(100):\n",
        "    stop=False\n",
        "    ch='\\t'\n",
        "    counter=1\n",
        "    \n",
        "    #initialize the target sequence with a tab character\n",
        "    target_seq = np.zeros((1, max_len, 28))\n",
        "    target_seq[0, 0, char_to_ix[ch]] = 1.\n",
        "    \n",
        "    #generate the name one character at a time until a newline character is encountered or the name exceeds 10 characters\n",
        "    while stop == False and counter < 10:\n",
        "        \n",
        "        #use the model to predict the probabilities of the next character\n",
        "        probs = model.predict(target_seq, verbose=0)[:,counter-1,:]\n",
        "        \n",
        "        #sample the next character based on the predicted probabilities\n",
        "        c= np.random.choice(sorted(list(all_chars_female)), replace =False,p=probs.reshape(28))\n",
        "        \n",
        "        #newline character is generated, stop generating the name\n",
        "        if c =='\\n':\n",
        "            stop=True\n",
        "        else:\n",
        "            #append the generated character to the name\n",
        "            ch=ch+c\n",
        "            \n",
        "            #update the target sequence with the generated character\n",
        "            target_seq[0,counter , char_to_ix[c]] = 1.\n",
        "            \n",
        "            #increment the counter to move to the next character\n",
        "            counter=counter+1\n",
        "    \n",
        "    #append the generated name to the list of male names\n",
        "    female_names.append(ch)"
      ],
      "metadata": {
        "id": "5jBmANOCVnFM"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_female_names = []\n",
        "for i in female_names:\n",
        "  k = i.replace('\\t','')\n",
        "  new_female_names.append(k)"
      ],
      "metadata": {
        "id": "UqwtQPE1V2Sq"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_female_names = [name.capitalize() for name in new_female_names]\n",
        "print(len(generated_female_names))\n",
        "print(generated_female_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQiWNPRnV3dn",
        "outputId": "532080ed-a32c-4984-fc83-27b48c4bdb10"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100\n",
            "['Chonnke', 'Elonah', 'Tonnie', 'Chauntal', 'Shuntell', 'Giloda', 'Cathelyn', 'Kimod', 'Favah', 'Lizel', 'Mekrisle', 'Chrissa', 'Anyiah', 'Iiba', 'Winetta', 'Sharmyle', 'Ubiell', 'Tika', 'Aleiza', 'Louhela', 'Maiklen', 'Gwineen', 'Feydynn', 'Racqelia', 'Zayma', 'Arnely', 'Kanquett', 'Dawnie', 'Daleyeah', 'Biquaina', 'Sharona', 'Lakitsra', 'Bryttane', 'Genniell', 'Jella', 'Kasiyah', 'Yuquita', 'Jasena', 'Tehrei', 'Keirrah', 'Jewellyn', 'Kallee', 'Ferled', 'Noel', 'Henayle', 'Karmshe', 'Tiffana', 'Breena', 'Laneta', 'Marchett', 'Yestafin', 'Malberan', 'Arnitza', 'Latrice', 'Chaitaly', 'Salena', 'Beorgina', 'Yeanna', 'Jachysel', 'Aliyana', 'Malynett', 'Mellore', 'Dely', 'Avinelle', 'Daiylee', 'Yaleber', 'Toshy', 'Kaylanna', 'Posiry', 'Karlkrin', 'Patziah', 'Bithlin', 'Kessija', 'Felicia', 'Jaselli', 'Cocelyn', 'Shyber', 'Samaha', 'Christy', 'Threes', 'Cathelen', 'Willow', 'Joi', 'Synessa', 'Anajuh', 'Measia', 'Taytina', 'Irzetta', 'Madyli', 'Hemo', 'Femeri', 'Lachinle', 'Nikolyn', 'Ebagolly', 'Radah', 'Teneta', 'Zahyria', 'Kastyne', 'Briehann', 'Littfini']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing "
      ],
      "metadata": {
        "id": "eAGEZJlkcWVt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#converting into dataframe\n",
        "df_female = pd.DataFrame(generated_female_names, columns = ['name'])"
      ],
      "metadata": {
        "id": "FcSjpDh2cVkn"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_female['gender'] = np.repeat('F', 100)"
      ],
      "metadata": {
        "id": "M9C9rF3acfo8"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_female.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QeLIXkuWcl1W",
        "outputId": "3a6dca96-ebac-43c0-e77c-1e17e566fc92"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       name gender\n",
              "0   Chonnke      F\n",
              "1    Elonah      F\n",
              "2    Tonnie      F\n",
              "3  Chauntal      F\n",
              "4  Shuntell      F"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3c6fffd-a990-4609-a9a7-083b0abb6546\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Chonnke</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Elonah</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tonnie</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chauntal</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Shuntell</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3c6fffd-a990-4609-a9a7-083b0abb6546')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c3c6fffd-a990-4609-a9a7-083b0abb6546 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c3c6fffd-a990-4609-a9a7-083b0abb6546');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove non-ASCII characters\n",
        "df_female['name'] = df_female['name'].apply(lambda x: ''.join([i for i in x if i in string.ascii_letters]))\n",
        "\n",
        "#convert each name into a sequence of one-hot encoded characters\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(df_female['name'])\n",
        "\n",
        "max_len = max([len(i) for i in df_female['name']])\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df_female['name'])\n",
        "X = pad_sequences(X, maxlen=max_len, padding='post')\n",
        "\n",
        "#create one-hot encoded representation\n",
        "X_one_hot= np.array([np.eye(vocab_size+1)[i] for i in X])\n",
        "\n",
        "#convert the labels to binary values\n",
        "y = pd.get_dummies(df_female['gender'])['F']\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "iEpK_zbhdF3r"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model on the test data\n",
        "loss, accuracy = lstm_model.evaluate(X, y, verbose=0)\n",
        "\n",
        "#print the results\n",
        "print(f\"Female Accuracy using LSTM: {accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMCRDazTfw_f",
        "outputId": "42f554f5-b90b-4c69-d0a8-39377d8054e5"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Female Accuracy using LSTM: 0.510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Measuring Combined Accuracy"
      ],
      "metadata": {
        "id": "rX4JG8SKmjVq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frames = [df_male, df_female]\n",
        "\n",
        "df_combined = pd.concat(frames)"
      ],
      "metadata": {
        "id": "818VDQ4Ymi1v"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df_combined))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpIU5nPfmhac",
        "outputId": "16d54cc2-822d-42bc-992b-1398e17b9adc"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#remove non-ASCII characters\n",
        "df_combined['name'] = df_combined['name'].apply(lambda x: ''.join([i for i in x if i in string.ascii_letters]))\n",
        "\n",
        "#convert each name into a sequence of one-hot encoded characters\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(df_combined['name'])\n",
        "\n",
        "max_len = max([len(i) for i in df_combined['name']])\n",
        "vocab_size = len(tokenizer.word_index)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(df_combined['name'])\n",
        "X = pad_sequences(X, maxlen=max_len, padding='post')\n",
        "\n",
        "#create one-hot encoded representation\n",
        "X_one_hot= np.array([np.eye(vocab_size+1)[i] for i in X])\n",
        "\n",
        "#convert the labels to binary values\n",
        "y = pd.get_dummies(df_combined['gender'])['F']\n",
        "y = np.array(y)"
      ],
      "metadata": {
        "id": "DYYYl_O6nBfl"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate the model on the test data\n",
        "loss, accuracy = lstm_model.evaluate(X, y, verbose=0)\n",
        "\n",
        "#print the results\n",
        "print(f\"Combined Accuracy using LSTM: {accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Kv8EaIwnXvI",
        "outputId": "b499591a-0267-4fc2-b016-24e20e75ec3e"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combined Accuracy using LSTM: 0.580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The combined accuracy of 58% states the model performed decently well in generating new male and female names."
      ],
      "metadata": {
        "id": "SVnCUdoknvwl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problem Statement 2a"
      ],
      "metadata": {
        "id": "-ZdCUtCMf1Mz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "#load the dataset into a pandas dataframe\n",
        "df_ame = pd.read_csv('/content/name_gender.csv')\n",
        "\n",
        "#filter the dataframe to include only names that start with A, M, or Z\n",
        "df_ame = df_ame[df_ame['name'].str.startswith(('A', 'M', 'Z'))]\n",
        "\n",
        "#display the filtered dataframe\n",
        "print(len(df_ame))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wW51LTLaf7XL",
        "outputId": "321711ff-9004-4259-ce34-ff29b50ad42f"
      },
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ame.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "EMajmmmIgQ-i",
        "outputId": "49a0c5cc-cc9d-484f-d88f-79dcb9b087b9"
      },
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        name gender  probability\n",
              "0      Aaban      M          1.0\n",
              "1      Aabha      F          1.0\n",
              "2      Aabid      M          1.0\n",
              "3  Aabriella      F          1.0\n",
              "4       Aada      F          1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3956f776-9e23-429c-bcc2-c14651568d6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>gender</th>\n",
              "      <th>probability</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Aaban</td>\n",
              "      <td>M</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Aabha</td>\n",
              "      <td>F</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Aabid</td>\n",
              "      <td>M</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Aabriella</td>\n",
              "      <td>F</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Aada</td>\n",
              "      <td>F</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3956f776-9e23-429c-bcc2-c14651568d6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3956f776-9e23-429c-bcc2-c14651568d6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3956f776-9e23-429c-bcc2-c14651568d6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_ame_names = df_ame['name']"
      ],
      "metadata": {
        "id": "KQuIVZHEgT_6"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ame_names = df_ame_names.apply(lambda x: x.lower())"
      ],
      "metadata": {
        "id": "gNssM83SgXO2"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ame_names=pd.DataFrame({'name':df_ame_names.unique()})"
      ],
      "metadata": {
        "id": "zWzh-ZCWgbbJ"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to delay target by one timestamp\n",
        "df_ame_names['name']=df_ame_names.name.apply(lambda x:'\\t'+x)\n",
        "\n",
        "#to indicate end of the word\n",
        "df_ame_names['target']=df_ame_names.name.apply(lambda x:x[1:len(x)]+'\\n')"
      ],
      "metadata": {
        "id": "oMdLlRK2gyK2"
      },
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a list\n",
        "lenght_list_ame=[]\n",
        "for l in df_ame_names.name:\n",
        "    lenght_list_ame.append(len(l))\n",
        "max_len = np.max(lenght_list_ame)\n",
        "\n",
        "#the vocab dict\n",
        "all_chars_ame=set()\n",
        "for name in df_ame_names.name:\n",
        "    for c in name:\n",
        "        if c not in all_chars_ame:\n",
        "            all_chars_ame.add(c)\n",
        "all_chars_ame.add('\\n')\n",
        "\n",
        "char_to_ix = { ch:i for i,ch in enumerate(sorted(all_chars_ame)) }\n",
        "ix_to_char = { i:ch for i,ch in enumerate(sorted(all_chars_ame)) }"
      ],
      "metadata": {
        "id": "cBqmkpqug2uP"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = np.zeros((len(df_ame_names.name), max_len, 28),dtype='float32')\n",
        "output_data = np.zeros((len(df_ame_names.name), max_len, 28),dtype='float32')\n",
        "\n",
        "#generate input and output data\n",
        "for i, x in enumerate(df_ame_names.name):\n",
        "    for t, ch in enumerate(x):\n",
        "        input_data[i, t, char_to_ix[ch]] = 1\n",
        "for i, x in enumerate(df_ame_names.target):\n",
        "    for t, ch in enumerate(x):\n",
        "        output_data[i,t, char_to_ix[ch]] = 1"
      ],
      "metadata": {
        "id": "kClEI3jqg3To"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model for generating new names\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(50, input_shape=(max_len, len(all_chars_male)), return_sequences=True))\n",
        "model_lstm.add(TimeDistributed(Dense(len(all_chars_male))))\n",
        "model_lstm.add(TimeDistributed(Activation('softmax')))\n",
        "optimizer = RMSprop(lr=0.01)\n",
        "model_lstm.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmXPpux3hi2x",
        "outputId": "a4b1a239-c3fa-4b77-cb75-77ea65191faf"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super().__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "model_lstm.fit(input_data, output_data, batch_size=32,epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4Uo1dXdhs1y",
        "outputId": "ae588e61-62b8-40bc-f3a2-1b774bd93b48"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "597/597 [==============================] - 10s 13ms/step - loss: 0.9441\n",
            "Epoch 2/50\n",
            "597/597 [==============================] - 7s 12ms/step - loss: 0.8680\n",
            "Epoch 3/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.8471\n",
            "Epoch 4/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.8353\n",
            "Epoch 5/50\n",
            "597/597 [==============================] - 6s 11ms/step - loss: 0.8269\n",
            "Epoch 6/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.8204\n",
            "Epoch 7/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.8152\n",
            "Epoch 8/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.8113\n",
            "Epoch 9/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.8079\n",
            "Epoch 10/50\n",
            "597/597 [==============================] - 8s 14ms/step - loss: 0.8050\n",
            "Epoch 11/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.8026\n",
            "Epoch 12/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.8009\n",
            "Epoch 13/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7988\n",
            "Epoch 14/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.7970\n",
            "Epoch 15/50\n",
            "597/597 [==============================] - 8s 14ms/step - loss: 0.7954\n",
            "Epoch 16/50\n",
            "597/597 [==============================] - 7s 12ms/step - loss: 0.7940\n",
            "Epoch 17/50\n",
            "597/597 [==============================] - 7s 12ms/step - loss: 0.7925\n",
            "Epoch 18/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7913\n",
            "Epoch 19/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.7905\n",
            "Epoch 20/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7894\n",
            "Epoch 21/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.7885\n",
            "Epoch 22/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7877\n",
            "Epoch 23/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7869\n",
            "Epoch 24/50\n",
            "597/597 [==============================] - 9s 15ms/step - loss: 0.7865\n",
            "Epoch 25/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7859\n",
            "Epoch 26/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.7850\n",
            "Epoch 27/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7842\n",
            "Epoch 28/50\n",
            "597/597 [==============================] - 7s 12ms/step - loss: 0.7841\n",
            "Epoch 29/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7836\n",
            "Epoch 30/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7833\n",
            "Epoch 31/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.7825\n",
            "Epoch 32/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7819\n",
            "Epoch 33/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.7820\n",
            "Epoch 34/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7813\n",
            "Epoch 35/50\n",
            "597/597 [==============================] - 7s 12ms/step - loss: 0.7809\n",
            "Epoch 36/50\n",
            "597/597 [==============================] - 10s 16ms/step - loss: 0.7807\n",
            "Epoch 37/50\n",
            "597/597 [==============================] - 8s 14ms/step - loss: 0.7801\n",
            "Epoch 38/50\n",
            "597/597 [==============================] - 13s 21ms/step - loss: 0.7799\n",
            "Epoch 39/50\n",
            "597/597 [==============================] - 7s 12ms/step - loss: 0.7801\n",
            "Epoch 40/50\n",
            "597/597 [==============================] - 9s 14ms/step - loss: 0.7793\n",
            "Epoch 41/50\n",
            "597/597 [==============================] - 7s 12ms/step - loss: 0.7793\n",
            "Epoch 42/50\n",
            "597/597 [==============================] - 7s 12ms/step - loss: 0.7790\n",
            "Epoch 43/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7787\n",
            "Epoch 44/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.7785\n",
            "Epoch 45/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7782\n",
            "Epoch 46/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.7781\n",
            "Epoch 47/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7776\n",
            "Epoch 48/50\n",
            "597/597 [==============================] - 7s 11ms/step - loss: 0.7771\n",
            "Epoch 49/50\n",
            "597/597 [==============================] - 8s 13ms/step - loss: 0.7776\n",
            "Epoch 50/50\n",
            "597/597 [==============================] - 7s 12ms/step - loss: 0.7773\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbb7de4c280>"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating"
      ],
      "metadata": {
        "id": "W1RXPv2Mhz7P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize an empty list to store generated male names\n",
        "ame_names = []\n",
        "\n",
        "#generate 100 male names\n",
        "for i in range(50):\n",
        "    stop=False\n",
        "    ch='\\t'\n",
        "    counter=1\n",
        "    \n",
        "    #initialize the target sequence with a tab character\n",
        "    target_seq = np.zeros((1, max_len, 28))\n",
        "    target_seq[0, 0, char_to_ix[ch]] = 1.\n",
        "    \n",
        "    #generate the name one character at a time until a newline character is encountered or the name exceeds 10 characters\n",
        "    while stop == False and counter < 16:\n",
        "        \n",
        "        #use the model to predict the probabilities of the next character\n",
        "        probs = model.predict(target_seq, verbose=0)[:,counter-1,:]\n",
        "        \n",
        "        #sample the next character based on the predicted probabilities\n",
        "        c= np.random.choice(sorted(list(all_chars_female)), replace =False,p=probs.reshape(28))\n",
        "        \n",
        "        #newline character is generated, stop generating the name\n",
        "        if c =='\\n':\n",
        "            stop=True\n",
        "        else:\n",
        "            #append the generated character to the name\n",
        "            ch=ch+c\n",
        "            \n",
        "            #update the target sequence with the generated character\n",
        "            target_seq[0,counter , char_to_ix[c]] = 1.\n",
        "            \n",
        "            #increment the counter to move to the next character\n",
        "            counter=counter+1\n",
        "    \n",
        "    #append the generated name to the list of male names\n",
        "    ame_names.append(ch)"
      ],
      "metadata": {
        "id": "PDjSYbSUh33f"
      },
      "execution_count": 237,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_ame_names = []\n",
        "for i in ame_names:\n",
        "  k = i.replace('\\t','')\n",
        "  new_ame_names.append(k)"
      ],
      "metadata": {
        "id": "g8m423ych51h"
      },
      "execution_count": 238,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_ame_names = [name.capitalize() for name in new_ame_names]\n",
        "print(len(generated_ame_names))\n",
        "print(generated_ame_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP7b7x4ciCFV",
        "outputId": "b6e73de5-eac4-4384-c339-6fb6370a8c6d"
      },
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n",
            "['Asadelle', 'Alfreedaz', 'Melissia', 'Arron', 'Angelieja', 'Mitsurd', 'Anallys', 'Melieka', 'Mckiul', 'Zekiyah', 'Magrabella', 'Almilli', 'Menune', 'Amareya', 'Aleivah', 'Metiangel', 'Adhrin', 'Abbe', 'Alyciana', 'Angelise', 'Alan', 'Melahmat', 'Annalise', 'Mirial', 'Ahbree', 'Maudina', 'Aneanton', 'Munashak', 'Alaynna', 'Art', 'Anneeka', 'Alayziah', 'Moess', 'Allie', 'Zyaira', 'Zyane', 'Anfruna', 'Zaavin', 'Mebosa', 'Antoniebardhan', 'Mjio', 'Ametalen', 'Zinakiah', 'Moika', 'Marinell', 'Araston', 'Meynah', 'Avelleah', 'Azalee', 'Zenackahide']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perplexity"
      ],
      "metadata": {
        "id": "J9rFdeJLqjfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def cal_perplexity(model, max_len, char_to_ix, names):\n",
        "  \n",
        "    total_loss = 0.0\n",
        "    total_chars = 0\n",
        "    \n",
        "    for name in names:\n",
        "        #initialize the target sequence with a tab character\n",
        "        target_seq = np.zeros((1, max_len, len(char_to_ix)))\n",
        "        target_seq[0, 0, char_to_ix['\\t']] = 1.\n",
        "\n",
        "        #generate the name one character at a time until a newline character is encountered or the name exceeds max_len\n",
        "        for t in range(1, max_len):\n",
        "            #use the model to predict the probabilities of the next character\n",
        "            probs = model.predict(target_seq, verbose=0)[:, t-1, :]\n",
        "            #get the index of the true next character\n",
        "            true_idx = char_to_ix[name[t-1]]\n",
        "            #get the probability of the true next character\n",
        "            true_prob = probs[0, true_idx]\n",
        "            #update the total loss with the negative log probability of the true next character\n",
        "            total_loss -= np.log(true_prob)\n",
        "            #increment the total number of characters seen\n",
        "            total_chars += 1\n",
        "            #update the target sequence with the true next character\n",
        "            target_seq[0, t, true_idx] = 1.\n",
        "\n",
        "            #if newline character is generated, stop generating the name\n",
        "            if name[t-1] == '\\n':\n",
        "                break\n",
        "        \n",
        "    #calculate the perplexity as the exponential of the average cross-entropy loss per character\n",
        "    perplexity = np.exp(total_loss / total_chars)\n",
        "    \n",
        "    return perplexity"
      ],
      "metadata": {
        "id": "-huAjcnyD9xt"
      },
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len_list=[]\n",
        "for i in ame_names:\n",
        "    max_len_list.append(len(i))\n",
        "max_len_gen = np.max(max_len_list)"
      ],
      "metadata": {
        "id": "JXfDSXJoMWWt"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average perplexity\n",
        "perplexity = cal_perplexity(model_lstm, max_len, char_to_ix, ame_names)\n",
        "\n",
        "print(\"Perplexity:\", perplexity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCH3G9cSEBBW",
        "outputId": "532d069c-9ece-484a-8e2d-5f92880b47c0"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perplexity: 510.26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Therefore the average perplexity value of generated names is 510.26"
      ],
      "metadata": {
        "id": "uT04R5evTWF0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}